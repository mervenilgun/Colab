from openai import OpenAI
from dotenv import load_dotenv
import os

# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# 1ï¸âƒ£ Zero-shot Prompt
zero_shot = "Ä°klim deÄŸiÅŸikliÄŸi nedir?"

# 2ï¸âƒ£ Few-shot Prompt
few_shot = (
    "Soru: Sera gazÄ± nedir?\n"
    "Cevap: Atmosferde Ä±sÄ±yÄ± tutan gazlardÄ±r.\n"
    "Soru: Ozon tabakasÄ± ne iÅŸe yarar?\n"
    "Cevap: ZararlÄ± UV Ä±ÅŸÄ±nlarÄ±nÄ± engeller.\n"
    "Soru: Ä°klim deÄŸiÅŸikliÄŸi nedir?\n"
    "Cevap:"
)

# 3ï¸âƒ£ Chain of Thought Prompt
chain_of_thought = (
    "Soru: Ä°klim deÄŸiÅŸikliÄŸi nedir?\n"
    "DÃ¼ÅŸÃ¼n: Atmosferdeki sera gazlarÄ± gÃ¼neÅŸ Ä±ÅŸÄ±nlarÄ±nÄ± tutar. "
    "Bu gazlarÄ±n artÄ±ÅŸÄ±, sÄ±caklÄ±klarÄ± yÃ¼kseltir ve mevsimler deÄŸiÅŸir.\n"
    "Cevap:"
)

# LLM'den yanÄ±t al
def get_completion(prompt):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )
    return response.choices[0].message.content.strip()

# YanÄ±tlarÄ± yazdÄ±r
print("ğŸ”µ Zero-shot:\n", get_completion(zero_shot), "\n")
print("ğŸŸ¡ Few-shot:\n", get_completion(few_shot), "\n")
print("ğŸ”— Chain of Thought:\n", get_completion(chain_of_thought), "\n")
