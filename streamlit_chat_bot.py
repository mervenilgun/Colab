# pip install streamlit langchain langchain-openai python-dotenv

import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from dotenv import load_dotenv
import os

# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

# LLM tanÄ±mÄ±
llm = ChatOpenAI(model="gpt-4", temperature=0.7)

# Streamlit baÅŸlÄ±ÄŸÄ±
st.set_page_config(page_title="BaÄŸlamlÄ± Chat AsistanÄ±", layout="wide")
st.title("ğŸ’¬ BaÄŸlamlÄ± Yapay ZekÃ¢ AsistanÄ±")

# SessionState iÃ§inde memory objesi oluÅŸtur
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(
        memory_key="chat_history", return_messages=True
    )

# KullanÄ±cÄ±dan giriÅŸ al
user_input = st.text_input("ğŸ‘¤ Sorunuzu yazÄ±n", placeholder="Ã–rneÄŸin: Fransa'nÄ±n baÅŸkenti nedir?", key="input")

# GÃ¶nder butonuna basÄ±ldÄ±ÄŸÄ±nda Ã§alÄ±ÅŸÄ±r
if st.button("GÃ¶nder") and user_input.strip():
    memory = st.session_state.memory

    # GeÃ§miÅŸ konuÅŸmalarÄ± al ve biÃ§imlendir
    history = memory.load_memory_variables({})["chat_history"]
    formatted_history = "\n".join([f"{m.type.capitalize()}: {m.content}" for m in history])

    # Model iÃ§in Ã¶zel prompt
    full_prompt = (
        f"AÅŸaÄŸÄ±da bir kullanÄ±cÄ±yla Ã¶nceki konuÅŸmalar yer alÄ±yor.\n"
        f"{formatted_history}\n\n"
        f"KullanÄ±cÄ±nÄ±n yeni sorusu: {user_input}\n"
        f"GeÃ§miÅŸ konuÅŸmalara uygun ve baÄŸlamlÄ± TÃ¼rkÃ§e bir cevap ver."
    )

    # Model cevabÄ±
    try:
        response = llm.invoke(full_prompt)
        st.session_state.memory.chat_memory.add_user_message(user_input)
        st.session_state.memory.chat_memory.add_ai_message(response.content)

        # Son cevabÄ± gÃ¶ster
        st.markdown(f"**ğŸ¤– Cevap:** {response.content}")

    except Exception as e:
        st.error(f"âŒ Hata oluÅŸtu: {e}")

# GeÃ§miÅŸ sohbeti gÃ¶ster (isteÄŸe baÄŸlÄ±)
with st.expander("ğŸ§  Sohbet GeÃ§miÅŸi"):
    for msg in st.session_state.memory.chat_memory.messages:
        role = "ğŸ‘¤" if msg.type == "human" else "ğŸ¤–"
        st.markdown(f"{role} {msg.content}")
